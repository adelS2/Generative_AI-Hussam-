{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs) and Their Variants\n",
    "\n",
    "Welcome to this notebook on Generative Adversarial Networks (GANs)! In this notebook, we will:\n",
    "\n",
    "- Introduce the basic architecture of GANs, including the roles of the **Generator** and **Discriminator**\n",
    "- Explain the training process and key challenges\n",
    "- Implement a simple GAN (using a DCGAN-style architecture) on a dataset (e.g., MNIST)\n",
    "- Discuss common GAN variants such as Conditional GANs, CycleGANs, and others\n",
    "\n",
    "This notebook is designed for a practical, hands-on course in generative AI and avoids deep mathematical details while providing sufficient background to work with and build generative models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gan-overview",
   "metadata": {},
   "source": [
    "## 1. Introduction to GANs\n",
    "\n",
    "Generative Adversarial Networks (GANs) were introduced by Ian Goodfellow in 2014. The core idea is to have two neural networks—a **Generator** and a **Discriminator**—competing against each other:\n",
    "\n",
    "- **Generator (G):** Takes in random noise (from a latent space) and attempts to generate realistic data (e.g., images).\n",
    "- **Discriminator (D):** Receives both real data (from the training set) and fake data (produced by the generator) and tries to distinguish between the two.\n",
    "\n",
    "During training, G improves at fooling D, while D gets better at detecting fakes. This adversarial process drives the generator to produce increasingly realistic outputs.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **Adversarial Loss:** Both networks are trained with opposing objectives. The generator’s loss is designed to maximize the discriminator’s error, while the discriminator minimizes classification errors.\n",
    "- **Training Challenges:** GANs are notoriously difficult to train due to issues such as mode collapse, non-convergence, and delicate balance between the two networks.\n",
    "\n",
    "In the following sections, we will build a simple GAN, explore its components, and then briefly discuss variants that extend the basic idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 2. Environment Setup and Imports\n",
    "\n",
    "We'll be using PyTorch for our implementation. Make sure you have the following libraries installed:\n",
    "\n",
    "- `torch`\n",
    "- `torchvision`\n",
    "- `matplotlib`\n",
    "- `numpy`\n",
    "\n",
    "Let's import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set manual seed for reproducibility\n",
    "manualSeed = 999\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "For this demonstration, we will use the MNIST dataset. Later, you could try using other datasets (e.g., CelebA) to see how the model adapts to more complex images.\n",
    "\n",
    "We will normalize the images to the range [-1, 1] (a common practice for GANs) and load the data using PyTorch’s `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "image_size = 28\n",
    "nc = 1  # number of channels for MNIST (grayscale)\n",
    "nz = 100  # size of the latent z vector\n",
    "\n",
    "# Create the dataset\n",
    "dataset = dsets.MNIST(root='./data', train=True, download=True, \n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.Resize(image_size),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5,), (0.5,))\n",
    "                        ]))\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gan-models",
   "metadata": {},
   "source": [
    "## 4. Defining the GAN Architecture\n",
    "\n",
    "We will now define the **Generator** and **Discriminator** networks. For this example, we use a simple architecture similar to that of a Deep Convolutional GAN (DCGAN), adapted for MNIST.\n",
    "\n",
    "### Generator\n",
    "\n",
    "The generator takes a latent vector (random noise) as input and produces an image. We use a series of transposed convolutions to upsample the latent space to the image dimensions.\n",
    "\n",
    "### Discriminator\n",
    "\n",
    "The discriminator is a convolutional network that takes an image as input and outputs a single scalar representing the probability that the input is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generator Code\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, 7, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State size: (ngf*4) x 7 x 7\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State size: (ngf*2) x 14 x 14\n",
    "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # Output size: nc x 28 x 28\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "## Discriminator Code\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is nc x 28 x 28\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State size: ndf x 14 x 14\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State size: (ndf*2) x 7 x 7\n",
    "            nn.Conv2d(ndf * 2, 1, 7, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {},
   "source": [
    "## 5. Training the GAN\n",
    "\n",
    "We now define the training loop. In each iteration:\n",
    "\n",
    "1. **Discriminator Training:**\n",
    "   - Train on real images from the dataset\n",
    "   - Train on fake images produced by the generator\n",
    "2. **Generator Training:**\n",
    "   - Update the generator to produce images that fool the discriminator\n",
    "\n",
    "For simplicity, we use the Binary Cross Entropy loss. You may explore other loss functions in advanced exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4180304",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "**Steps per Batch:**\n",
    "1. **Train the Discriminator:**  \n",
    "   - Use a batch of real images and label them as 1.\n",
    "   - Generate a batch of fake images from noise and label them as 0.\n",
    "   - Compute loss and backpropagate.\n",
    "2. **Train the Generator:**  \n",
    "   - Generate a batch of fake images.\n",
    "   - Compute the loss against a target label of 1 (i.e., tricking the discriminator).\n",
    "   - Backpropagate and update weights.\n",
    "**Logging:**  \n",
    "We log key metrics (losses, sample images) to wandb to track training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the model architecture\n",
    "ngf = 64  # Generator feature map size\n",
    "ndf = 64  # Discriminator feature map size\n",
    "\n",
    "# Create the generator\n",
    "netG = Generator(nz, ngf, nc).to(device)\n",
    "print(netG)\n",
    "\n",
    "# Create the discriminator\n",
    "netD = Discriminator(nc, ndf).to(device)\n",
    "print(netD)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Setup optimizers for both G and D\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 5  # Adjust epochs as needed\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "img_list = []\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ############################\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        # Train with real images\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        \n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        # Train with fake images\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ############################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # Generator wants the discriminator to think these are real\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 100 == 0:\n",
    "            print(f'[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(dataloader)}] ' \n",
    "                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} ' \n",
    "                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "    \n",
    "    # Save generator's output on fixed_noise for visualization\n",
    "    with torch.no_grad():\n",
    "        fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "# Plot some generated images\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variants",
   "metadata": {},
   "source": [
    "## 6. Exploring GAN Variants\n",
    "\n",
    "Once you are comfortable with the basic GAN, you may explore the following variants:\n",
    "\n",
    "- **Conditional GANs (cGANs):** Generate images conditioned on labels. For example, generate MNIST digits conditioned on the digit label.\n",
    "- **DCGAN:** The architecture we used here is inspired by DCGAN. For higher resolution images, deeper networks may be needed.\n",
    "- **CycleGAN:** Used for image-to-image translation without paired examples (e.g., converting horses to zebras).\n",
    "- **InfoGAN:** Designed to learn interpretable and disentangled representations by maximizing mutual information.\n",
    "\n",
    "### Hands-On Exercise\n",
    "\n",
    "1. Modify the generator and discriminator to accept label information (i.e., implement a conditional GAN on MNIST).\n",
    "2. Experiment with different loss functions or network architectures to see how the output quality changes.\n",
    "3. Try using a different dataset (such as CelebA) and adjust the network layers accordingly.\n",
    "\n",
    "Each variant introduces new challenges and techniques that are valuable in professional AI work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "- The basic concept of GANs and their adversarial training process\n",
    "– How to implement a simple DCGAN on MNIST using PyTorch\n",
    "- An overview of popular GAN variants and ideas for further exploration\n",
    "\n",
    "### Recommended Tools and Platforms\n",
    "\n",
    "- **PyTorch / TensorFlow:** Frameworks for deep learning\n",
    "- **Weights & Biases or TensorBoard:** For tracking experiments\n",
    "- **Google Colab or Kaggle Kernels:** For running experiments in the cloud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
