{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3daaf42",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG): Enhancing LLMs with External Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad833a47",
   "metadata": {},
   "source": [
    "## Introduction to Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3169cd6f",
   "metadata": {},
   "source": [
    "> This course is heavily based on the WandB course [RAG++ : From POC to Production](https://wandb.ai/site/courses/rag/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e421a57",
   "metadata": {},
   "source": [
    "### What is Retrieval-Augmented Generation (RAG)?\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a technique used to enhance large language models (LLMs) by integrating external knowledge retrieved from document databases or knowledge stores. Unlike conventional generative models, which rely solely on learned parameters from training data, RAG dynamically accesses up-to-date and contextually relevant information, significantly improving the accuracy, reliability, and usefulness of the generated responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09bd27",
   "metadata": {},
   "source": [
    "The core idea behind RAG is simple yet powerful:\n",
    "\n",
    "- **Retrieve**: When a user provides a query or prompt, RAG first retrieves relevant documents or passages from an external knowledge base.\n",
    "\n",
    "- **Generate**: The model then uses the retrieved documents as context to generate accurate, informed, and detailed responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7ada5",
   "metadata": {},
   "source": [
    "### Why Retrieval Matters in Generative AI?\n",
    "\n",
    "Retrieval methods address fundamental limitations of purely parametric generative models:\n",
    "\n",
    "* **Factual Accuracy**: Retrieval enables models to access the latest and accurate data rather than relying solely on outdated training datasets.\n",
    "* **Reducing Hallucinations**: By grounding generation in retrieved information, RAG significantly reduces the chances of generating incorrect, nonsensical, or fabricated information.\n",
    "* **Scalability**: Retrieval allows LLMs to leverage large-scale, dynamic knowledge bases efficiently without retraining the entire model when information updates occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f692f38",
   "metadata": {},
   "source": [
    "### Limitations of Traditional LLMs:\n",
    "\n",
    "Traditional language models have some well-known drawbacks:\n",
    "\n",
    "* **Hallucination**: Generating plausible but incorrect or unsupported information.\n",
    "* **Stale Knowledge**: Limited to static training data, lacking awareness of recent updates or newly available information.\n",
    "* **Context Limitations**: Without retrieval, LLMs have fixed-size context windows, severely limiting their ability to reference extensive external knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a445ec3",
   "metadata": {},
   "source": [
    "### Real-world Examples and Use Cases\n",
    "\n",
    "**Knowledge-base Q&A Systems**\n",
    "* Quickly answering user questions by retrieving precise, authoritative information from structured or unstructured sources.\n",
    "* Example: Customer support systems retrieving relevant FAQ or product manuals to answer customer queries.\n",
    "\n",
    "**Chatbots with External Knowledge Bases**\n",
    "* Dynamic chatbots integrated with knowledge bases or external databases to offer up-to-date, personalized interactions.\n",
    "* Example: Travel assistant chatbot retrieving flight schedules, weather data, and travel restrictions.\n",
    "\n",
    "**Enterprise-level AI Assistants**\n",
    "* Assisting professionals in fields such as law, medicine, or technical documentation by providing quick access to domain-specific knowledge.\n",
    "* Example: Medical assistants that generate treatment suggestions based on the latest clinical guidelines and patient histories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fefb9",
   "metadata": {},
   "source": [
    "## Core Concepts and Components of RAG\n",
    "\n",
    "To effectively build and deploy Retrieval-Augmented Generation systems, itâ€™s crucial to understand their core components: the **Retriever**, the **Generator (Reader)**, and the overall **End-to-End Flow**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe900098",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "\n",
    "The retriever component is responsible for identifying and fetching the most relevant documents or information chunks from an external knowledge base given a query. Retrieval methods typically fall into two categories: **Sparse** and **Dense**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf04eb",
   "metadata": {},
   "source": [
    "##### Sparse Methods (Keyword-Based):\n",
    "\n",
    "Sparse retrieval methods rely on exact term matches and statistical weighting (like TF-IDF or BM25).\n",
    "\n",
    "* **TF-IDF**: Scores words based on frequency across documents.\n",
    "* **BM25**: An improvement that adjusts for document length and term saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53fa875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary terms:\n",
      "\n",
      "['and' 'are' 'cat' 'cats' 'companions' 'dogs' 'lovely' 'mat' 'on' 'pets'\n",
      " 'red' 'sat' 'soft' 'the' 'was']\n",
      "\n",
      "TF-IDF Weighted Document-Term Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>cat</th>\n",
       "      <th>cats</th>\n",
       "      <th>companions</th>\n",
       "      <th>dogs</th>\n",
       "      <th>lovely</th>\n",
       "      <th>mat</th>\n",
       "      <th>on</th>\n",
       "      <th>pets</th>\n",
       "      <th>red</th>\n",
       "      <th>sat</th>\n",
       "      <th>soft</th>\n",
       "      <th>the</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     and    are    cat   cats  companions   dogs  lovely    mat     on   pets  \\\n",
       "0  0.000  0.000  0.405  0.000       0.000  0.000   0.000  0.319  0.405  0.000   \n",
       "1  0.401  0.401  0.000  0.509       0.000  0.509   0.000  0.000  0.000  0.401   \n",
       "2  0.357  0.000  0.000  0.000       0.000  0.000   0.000  0.357  0.000  0.000   \n",
       "3  0.000  0.438  0.000  0.000       0.555  0.000   0.555  0.000  0.000  0.438   \n",
       "\n",
       "     red    sat   soft    the    was  \n",
       "0  0.000  0.405  0.000  0.638  0.000  \n",
       "1  0.000  0.000  0.000  0.000  0.000  \n",
       "2  0.453  0.000  0.453  0.357  0.453  \n",
       "3  0.000  0.000  0.000  0.000  0.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample documents\n",
    "docs = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"Dogs and cats are pets.\",\n",
    "    \"The mat was red and soft.\",\n",
    "    \"Pets are lovely companions.\"\n",
    "]\n",
    "\n",
    "# Step 1: Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Step 3: Get the list of terms (features)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Step 4: Convert the TF-IDF matrix into a DataFrame for better readability\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=terms)\n",
    "\n",
    "# Step 5: Display the terms\n",
    "print(\"Vocabulary terms:\\n\")\n",
    "print(terms)\n",
    "\n",
    "# Step 6: Display the TF-IDF matrix nicely\n",
    "print(\"\\nTF-IDF Weighted Document-Term Matrix:\\n\")\n",
    "tfidf_df.round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860b6de",
   "metadata": {},
   "source": [
    "##### **Exercise**:\n",
    "Modify the above code to search which document is most relevant to the query: \"cats love mats\".\n",
    "(Hint: Vectorize the query and compute cosine similarity!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419852a",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "[RAG++ : From POC to Production](https://wandb.ai/site/courses/rag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
