{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f170a6",
   "metadata": {},
   "source": [
    "# From Pre-training to Fine-tuning: Practical Guide for Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4b8d7",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "By the end of this notebook, students will:\n",
    "\n",
    "* Understand the differences and purposes of pre-training, supervised fine-tuning (SFT), and preference-based training (DPO).\n",
    "* Be able to fine-tune small, efficient transformer models (SmolLM2-135M) on practical datasets.\n",
    "* Evaluate fine-tuned models quantitatively (perplexity/loss) and qualitatively (generation quality).\n",
    "* Get introduced to high-performance libraries (Unsloth) for efficient transformer fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1819a07",
   "metadata": {},
   "source": [
    "## Introduction and Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c1442",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://images.ctfassets.net/kftzwdyauwt9/40in10B8KtAGrQvwRv5cop/8241bb17c283dced48ea034a41d7464a/chatgpt_diagram_light.png?w=2048&q=80&fm=webp\" alt=\"ChatGPT training phases\" width=\"1200\" />\n",
    "</div>\n",
    "\n",
    "Image source: [openai.com](https://openai.com/index/chatgpt/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7c937",
   "metadata": {},
   "source": [
    "### What is Pre-training?\n",
    "\n",
    "**Pre-training** is a process in which language models are initially trained on large-scale datasets using **self-supervised learning**. In simple terms, these models learn directly from the text itself without explicit labels provided by humans.\n",
    "\n",
    "Common pre-training tasks include:\n",
    "\n",
    "* **Causal Language Modeling (CLM):** Predicting the next word/token based on previous context.\n",
    "\n",
    "* **Masked Language Modeling (MLM):** Predicting hidden (masked) words in a sentence (e.g., used by BERT).\n",
    "\n",
    "Through pre-training, models capture fundamental language understanding, grammar, reasoning, and context comprehension. This general knowledge becomes the basis for further specialization through fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b80ab",
   "metadata": {},
   "source": [
    "#### SmolLM2 (Small and Efficient Model)\n",
    "\n",
    "In this course, weâ€™ll use SmolLM2-135M, a compact and efficient transformer-based language model developed specifically to offer robust performance on modest hardware resources. SmolLM2 balances capability and efficiency, making it ideal for educational purposes, prototyping, and running on limited hardware (e.g., GPUs available via Colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f28f8",
   "metadata": {},
   "source": [
    "### What is Supervised Fine-Tuning (SFT)?\n",
    "\n",
    "Although pre-trained models have broad language capabilities, they often lack task-specific accuracy. **Supervised Fine-Tuning (SFT)** bridges this gap, refining the general knowledge learned during pre-training by training the model further on task-specific data with explicit labels or prompts.\n",
    "\n",
    "Through fine-tuning, models become adept at specialized tasks, such as:\n",
    "\n",
    "* Conversational assistants\n",
    "* Text summarization\n",
    "* Sentiment analysis\n",
    "* Domain-specific language generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeca4e5",
   "metadata": {},
   "source": [
    "#### SmolTalk Dataset\n",
    "\n",
    "In this notebook, we'll practically perform supervised fine-tuning using **SmolTalk**, a compact conversational dataset designed specifically for fine-tuning lightweight language models. SmolTalk is carefully crafted to provide realistic conversational exchanges, helping our SmolLM2 model improve significantly in generating natural dialogues and responding to instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f76cdf",
   "metadata": {},
   "source": [
    "### Preference-based Fine-tuning (DPO)\n",
    "\n",
    "Beyond supervised fine-tuning, recent approaches also incorporate **Preference-based Fine-tuning (DPO, Direct Preference Optimization)**. Instead of optimizing purely for task accuracy or next-token prediction, DPO fine-tunes models based on human-generated feedback indicating preference for specific responses.\n",
    "\n",
    "This method ensures models not only become task-specific but also align better with human preferences, improving their real-world usability, helpfulness, and alignment with ethical guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943eee0",
   "metadata": {},
   "source": [
    "#### UltraFeedback Dataset (Introduction)\n",
    "\n",
    "Later in our course, we will explore DPO practically using the **UltraFeedback dataset**, which contains numerous examples of human preferences ranking model-generated outputs. UltraFeedback helps models like SmolLM2 adapt to human-preferred conversational styles and improves their ability to generate helpful, appropriate, and aligned responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a4987",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/RvHjdlRT5gGQt5mJuhXH9.png\" alt=\"SmolLM2 Ecosystem\" width=\"1200\" />\n",
    "</div>\n",
    "\n",
    "Image source: [huggingface.co](https://huggingface.co/HuggingFaceTB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64815b",
   "metadata": {},
   "source": [
    "## Setup and Dataset Preparation\n",
    "\n",
    "In this section, you'll set up your environment by installing essential libraries and exploring the dataset (**SmolTalk**) we'll use for supervised fine-tuning (SFT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d68b7",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c273e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"train[:5000]\")\n",
    "pprint(dataset[0]['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d904f",
   "metadata": {},
   "source": [
    "Load **SmolLM2** Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c81e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c80e5",
   "metadata": {},
   "source": [
    "The loaded dataset contains conversations with distinct roles, which need to be formatted into a consistent text sequence before being fed into the language model.\n",
    "\n",
    "A **chat template** defines the structure for this formatting, ensuring uniformity in how roles are represented. Many tokenizers, including the SmolLM2 tokenizer, provide built-in methods for applying such templates.\n",
    "\n",
    "The SmolLM2 tokenizer includes a chat template specifically designed to align with its conversational style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tokenizer's apply_chat_template method (if provided)\n",
    "# We'll format the example as an instruction-response pair\n",
    "chat_example = dataset[0]['messages']\n",
    "\n",
    "# Check the default chat template (optional, but useful for inspection)\n",
    "formatted_input = tokenizer.apply_chat_template(chat_example, tokenize=False)\n",
    "print(\"\\nFormatted input with chat template:\\n\", formatted_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9e85d",
   "metadata": {},
   "source": [
    "Now, let's tokenize our dataset efficiently using the chat template. We'll define a tokenization function and apply it to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d348eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_with_chat_template(example):\n",
    "    # Use the tokenizer's apply_chat_template method to format the input\n",
    "    formatted_input = tokenizer.apply_chat_template(example['messages'], tokenize=False)\n",
    "    \n",
    "    # Tokenize the formatted input\n",
    "    tokenized_input = tokenizer(formatted_input, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    return tokenized_input\n",
    "\n",
    "# Tokenize the entire dataset using the custom function\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_with_chat_template,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb73c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ecad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fbdf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode back for sanity check\n",
    "decoded_sample = tokenizer.decode(tokenized_dataset[0]['input_ids'])\n",
    "print(\"\\nDecoded sample:\\n\", decoded_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./smollm2-sft-results\",   # Output directory for model checkpoints\n",
    "    num_train_epochs=3,                   # Number of epochs\n",
    "    learning_rate=3e-5,                   # Learning rate\n",
    "    weight_decay=0.01,                    # Weight decay for regularization\n",
    "    logging_steps=20,                     # How often to log training progress\n",
    "    save_steps=100,                       # How often to save checkpoints\n",
    "    fp16=True,                            # Enable mixed precision (faster training)\n",
    "    report_to=None,                       # Disable reporting to any platform (e.g., WandB, TensorBoard)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da680f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
