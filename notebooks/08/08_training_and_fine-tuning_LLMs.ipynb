{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussamalafandi/Generative_AI/blob/main/notebooks/08/08_training_and_fine-tuning_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f170a6",
      "metadata": {
        "id": "05f170a6"
      },
      "source": [
        "# From Pre-training to Fine-tuning: Practical Guide for Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd4b8d7",
      "metadata": {
        "id": "9fd4b8d7"
      },
      "source": [
        "## Learning Objectives:\n",
        "\n",
        "By the end of this notebook, students will:\n",
        "\n",
        "* Understand the differences and purposes of pre-training, supervised fine-tuning (SFT), and preference-based training (DPO).\n",
        "* Be able to fine-tune small, efficient transformer models (SmolLM2-135M) on practical datasets.\n",
        "* Evaluate fine-tuned models quantitatively (perplexity/loss) and qualitatively (generation quality).\n",
        "* Get introduced to high-performance libraries (Unsloth) for efficient transformer fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1819a07",
      "metadata": {
        "id": "d1819a07"
      },
      "source": [
        "## Introduction and Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644c1442",
      "metadata": {
        "id": "644c1442"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://images.ctfassets.net/kftzwdyauwt9/40in10B8KtAGrQvwRv5cop/8241bb17c283dced48ea034a41d7464a/chatgpt_diagram_light.png?w=2048&q=80&fm=webp\" alt=\"ChatGPT training phases\" width=\"1200\" />\n",
        "</div>\n",
        "\n",
        "Image source: [openai.com](https://openai.com/index/chatgpt/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c7c937",
      "metadata": {
        "id": "51c7c937"
      },
      "source": [
        "### What is Pre-training?\n",
        "\n",
        "**Pre-training** is a process in which language models are initially trained on large-scale datasets using **self-supervised learning**. In simple terms, these models learn directly from the text itself without explicit labels provided by humans.\n",
        "\n",
        "Common pre-training tasks include:\n",
        "\n",
        "* **Causal Language Modeling (CLM):** Predicting the next word/token based on previous context.\n",
        "\n",
        "* **Masked Language Modeling (MLM):** Predicting hidden (masked) words in a sentence (e.g., used by BERT).\n",
        "\n",
        "Through pre-training, models capture fundamental language understanding, grammar, reasoning, and context comprehension. This general knowledge becomes the basis for further specialization through fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "868b80ab",
      "metadata": {
        "id": "868b80ab"
      },
      "source": [
        "#### SmolLM2 (Small and Efficient Model)\n",
        "\n",
        "In this course, weâ€™ll use SmolLM2-135M, a compact and efficient transformer-based language model developed specifically to offer robust performance on modest hardware resources. SmolLM2 balances capability and efficiency, making it ideal for educational purposes, prototyping, and running on limited hardware (e.g., GPUs available via Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628f28f8",
      "metadata": {
        "id": "628f28f8"
      },
      "source": [
        "### What is Supervised Fine-Tuning (SFT)?\n",
        "\n",
        "Although pre-trained models have broad language capabilities, they often lack task-specific accuracy. **Supervised Fine-Tuning (SFT)** bridges this gap, refining the general knowledge learned during pre-training by training the model further on task-specific data with explicit labels or prompts.\n",
        "\n",
        "Through fine-tuning, models become adept at specialized tasks, such as:\n",
        "\n",
        "* Conversational assistants\n",
        "* Text summarization\n",
        "* Sentiment analysis\n",
        "* Domain-specific language generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbeca4e5",
      "metadata": {
        "id": "cbeca4e5"
      },
      "source": [
        "#### SmolTalk Dataset\n",
        "\n",
        "In this notebook, we'll practically perform supervised fine-tuning using **SmolTalk**, a compact conversational dataset designed specifically for fine-tuning lightweight language models. SmolTalk is carefully crafted to provide realistic conversational exchanges, helping our SmolLM2 model improve significantly in generating natural dialogues and responding to instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f76cdf",
      "metadata": {
        "id": "30f76cdf"
      },
      "source": [
        "### Preference-based Fine-tuning (DPO)\n",
        "\n",
        "Beyond supervised fine-tuning, recent approaches also incorporate **Preference-based Fine-tuning (DPO, Direct Preference Optimization)**. Instead of optimizing purely for task accuracy or next-token prediction, DPO fine-tunes models based on human-generated feedback indicating preference for specific responses.\n",
        "\n",
        "This method ensures models not only become task-specific but also align better with human preferences, improving their real-world usability, helpfulness, and alignment with ethical guidelines."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8943eee0",
      "metadata": {
        "id": "8943eee0"
      },
      "source": [
        "#### UltraFeedback Dataset (Introduction)\n",
        "\n",
        "Later in our course, we will explore DPO practically using the **UltraFeedback dataset**, which contains numerous examples of human preferences ranking model-generated outputs. UltraFeedback helps models like SmolLM2 adapt to human-preferred conversational styles and improves their ability to generate helpful, appropriate, and aligned responses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f69a4987",
      "metadata": {
        "id": "f69a4987"
      },
      "source": [
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/RvHjdlRT5gGQt5mJuhXH9.png\" alt=\"SmolLM2 Ecosystem\" width=\"1200\" />\n",
        "</div>\n",
        "\n",
        "Image source: [huggingface.co](https://huggingface.co/HuggingFaceTB)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f64815b",
      "metadata": {
        "id": "8f64815b"
      },
      "source": [
        "## Setup and Dataset Preparation\n",
        "\n",
        "In this section, you'll set up your environment by installing essential libraries and exploring the dataset (**SmolTalk**) we'll use for supervised fine-tuning (SFT)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-50XK7QHQN6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-50XK7QHQN6e",
        "outputId": "93ad14c4-c707-45ae-a2f1-fc441c5ab8e2"
      },
      "outputs": [],
      "source": [
        "%pip install transformers datasets trl torch torchvision huggingface_hub evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d03d68b7",
      "metadata": {
        "id": "d03d68b7"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b7c273e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7c273e2",
        "outputId": "ba43a5fb-4dd5-466d-e562-175eb905719e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': \"You're an AI assistant for text re-writing. Rewrite the input \"\n",
            "             'text to make it more concise while preserving its core meaning.',\n",
            "  'role': 'system'},\n",
            " {'content': 'Hey Alex,\\n'\n",
            "             '\\n'\n",
            "             \"I hope you're doing well! It's been a while since we met at the \"\n",
            "             'film festival last year. I was the one with the short film about '\n",
            "             \"the old abandoned factory. Anyway, I'm reaching out because I'm \"\n",
            "             'currently working on my thesis film project and I could really '\n",
            "             'use some advice on cinematography. I remember our conversation '\n",
            "             'about visual storytelling and I was hoping you might have some '\n",
            "             'tips or insights to share.\\n'\n",
            "             '\\n'\n",
            "             'My film is a drama set in a small town, and I want to capture '\n",
            "             'the mood and atmosphere of the location through my '\n",
            "             \"cinematography. I'm planning to shoot on location next month, \"\n",
            "             \"but I'm still trying to figure out the best way to approach it. \"\n",
            "             'If you have any suggestions or resources you could point me to, '\n",
            "             'I would be incredibly grateful.\\n'\n",
            "             '\\n'\n",
            "             \"Also, I heard from a mutual friend that you're having a \"\n",
            "             'photography exhibition soon. Congratulations! I would love to '\n",
            "             \"attend if you don't mind sending me the details.\\n\"\n",
            "             '\\n'\n",
            "             'Thanks in advance for any help you can provide. I really '\n",
            "             'appreciate it.\\n'\n",
            "             '\\n'\n",
            "             'Best,\\n'\n",
            "             'Jordan',\n",
            "  'role': 'user'},\n",
            " {'content': 'Hey Alex,\\n'\n",
            "             '\\n'\n",
            "             \"Hope you're well! It's Jordan from the film festival last year. \"\n",
            "             \"I'm working on my thesis film, a drama set in a small town, and \"\n",
            "             'could use your advice on cinematography to capture the mood and '\n",
            "             'atmosphere. Any tips or resources would be great.\\n'\n",
            "             '\\n'\n",
            "             \"Also, congrats on your upcoming photography exhibition! I'd love \"\n",
            "             'to attend; could you send me the details?\\n'\n",
            "             '\\n'\n",
            "             'Thanks a lot!\\n'\n",
            "             '\\n'\n",
            "             'Best,\\n'\n",
            "             'Jordan',\n",
            "  'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "train_dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"train\")\n",
        "eval_dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"test\")\n",
        "\n",
        "pprint(train_dataset[0]['messages'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845d904f",
      "metadata": {
        "id": "845d904f"
      },
      "source": [
        "Load **SmolLM2** Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8c81e241",
      "metadata": {
        "id": "8c81e241"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d9c80e5",
      "metadata": {
        "id": "6d9c80e5"
      },
      "source": [
        "The loaded dataset contains conversations with distinct roles, which need to be formatted into a consistent text sequence before being fed into the language model.\n",
        "\n",
        "A **chat template** defines the structure for this formatting, ensuring uniformity in how roles are represented. Many tokenizers, including the SmolLM2 tokenizer, provide built-in methods for applying such templates.\n",
        "\n",
        "The SmolLM2 tokenizer includes a chat template specifically designed to align with its conversational style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f6be5c39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6be5c39",
        "outputId": "3ef1cc2b-5ca1-48c4-a7ee-ea6224496cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Formatted input with chat template:\n",
            " <|im_start|>system\n",
            "You're an AI assistant for text re-writing. Rewrite the input text to make it more concise while preserving its core meaning.<|im_end|>\n",
            "<|im_start|>user\n",
            "Hey Alex,\n",
            "\n",
            "I hope you're doing well! It's been a while since we met at the film festival last year. I was the one with the short film about the old abandoned factory. Anyway, I'm reaching out because I'm currently working on my thesis film project and I could really use some advice on cinematography. I remember our conversation about visual storytelling and I was hoping you might have some tips or insights to share.\n",
            "\n",
            "My film is a drama set in a small town, and I want to capture the mood and atmosphere of the location through my cinematography. I'm planning to shoot on location next month, but I'm still trying to figure out the best way to approach it. If you have any suggestions or resources you could point me to, I would be incredibly grateful.\n",
            "\n",
            "Also, I heard from a mutual friend that you're having a photography exhibition soon. Congratulations! I would love to attend if you don't mind sending me the details.\n",
            "\n",
            "Thanks in advance for any help you can provide. I really appreciate it.\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Hey Alex,\n",
            "\n",
            "Hope you're well! It's Jordan from the film festival last year. I'm working on my thesis film, a drama set in a small town, and could use your advice on cinematography to capture the mood and atmosphere. Any tips or resources would be great.\n",
            "\n",
            "Also, congrats on your upcoming photography exhibition! I'd love to attend; could you send me the details?\n",
            "\n",
            "Thanks a lot!\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Using tokenizer's apply_chat_template method (if provided)\n",
        "# We'll format the example as an instruction-response pair\n",
        "chat_example = train_dataset[0]['messages']\n",
        "\n",
        "# Check the default chat template (optional, but useful for inspection)\n",
        "formatted_input = tokenizer.apply_chat_template(chat_example, tokenize=False)\n",
        "print(\"\\nFormatted input with chat template:\\n\", formatted_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d9e85d",
      "metadata": {
        "id": "d5d9e85d"
      },
      "source": [
        "Now, let's tokenize our dataset efficiently using the chat template. We'll define a tokenization function and apply it to the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d348eb5",
      "metadata": {
        "id": "7d348eb5",
        "outputId": "906778ae-0444-4177-d680-897a022a4abb"
      },
      "outputs": [],
      "source": [
        "def tokenize_with_chat_template(example):\n",
        "    # Use the tokenizer's apply_chat_template method to format the input\n",
        "    formatted_input = tokenizer.apply_chat_template(example['messages'], tokenize=False)\n",
        "\n",
        "    # Tokenize the formatted input\n",
        "    tokenized_input = tokenizer(formatted_input, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    return tokenized_input\n",
        "\n",
        "# Tokenize the entire dataset using the custom function\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenize_with_chat_template,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb73c8d",
      "metadata": {
        "id": "5eb73c8d"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4ecad7",
      "metadata": {
        "id": "5a4ecad7"
      },
      "outputs": [],
      "source": [
        "print(tokenized_dataset[0]['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fbdf6d",
      "metadata": {
        "id": "35fbdf6d"
      },
      "outputs": [],
      "source": [
        "# Decode back for sanity check\n",
        "decoded_sample = tokenizer.decode(tokenized_dataset[0]['input_ids'])\n",
        "print(\"\\nDecoded sample:\\n\", decoded_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bd5f6ea5",
      "metadata": {
        "id": "bd5f6ea5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3f70b9ee",
      "metadata": {
        "id": "3f70b9ee"
      },
      "outputs": [],
      "source": [
        "training_args = SFTConfig(\n",
        "    output_dir=\"./smollm2-sft-results\",   # Output directory for model checkpoints\n",
        "    num_train_epochs=3,                   # Number of epochs\n",
        "    learning_rate=3e-5,                   # Learning rate # try with 5e-5\n",
        "    logging_steps=10,                     # How often to log training progress\n",
        "    save_steps=100,                       # How often to save checkpoints\n",
        "    per_device_train_batch_size=4,        # Set according to your GPU memory capacity\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"steps\",                # Evaluate the model at regular intervals\n",
        "    eval_steps=50,                        # Frequency of evaluation\n",
        "    # gradient_accumulation_steps=4,\n",
        "    # gradient_checkpointing=True,\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da680f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "4da680f6",
        "outputId": "cc5b33f0-a848-49de-cdc4-7a567713ee1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='251' max='40008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  251/40008 14:34 < 38:47:25, 0.28 it/s, Epoch 0.02/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.978800</td>\n",
              "      <td>1.319638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.197300</td>\n",
              "      <td>1.244419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.180600</td>\n",
              "      <td>1.215166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.174200</td>\n",
              "      <td>1.196922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='314' max='351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [314/351 02:27 < 00:17, 2.12 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
