{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd35f7c",
   "metadata": {},
   "source": [
    "# RNNs for Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda9cc71",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "\n",
    "- Understand the motivation behind using Recurrent Neural Networks in NLP.\n",
    "- Explore key concepts: sequence modeling, recurrence, hidden states, backpropagation through time (briefly).\n",
    "- Implement RNN architectures (Simple RNN, LSTM) using PyTorch.\n",
    "- Train an RNN-based language model on real-world data.\n",
    "- Evaluate and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b06c20",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNNs) are specifically designed to handle sequential data—data where the order matters, such as text, audio, or time-series data. Unlike traditional neural networks that process input independently, RNNs maintain a hidden state that captures information about previous inputs, allowing them to model sequences effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11eaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import default_data_collator\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195373b",
   "metadata": {},
   "source": [
    "## Dataset: Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24649ece",
   "metadata": {},
   "source": [
    "We use the WikiText-2 dataset, a practical benchmark for language modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df18702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d9e0cb",
   "metadata": {},
   "source": [
    "Let's tokenize the data clearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7c7912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'input_ids'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "tokenized_datasets = datasets.map(\n",
    "    lambda x: tokenizer(x[\"text\"], return_attention_mask=False),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432283f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Valkyria Chronicles III = \\n</td>\n",
       "      <td>[796, 569, 18354, 7496, 17740, 6711, 796, 220,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senjō no Valkyria 3 : Unrecorded Chronicles (...</td>\n",
       "      <td>[2311, 73, 13090, 645, 569, 18354, 7496, 513, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The game began development in 2010 , carrying...</td>\n",
       "      <td>[383, 983, 2540, 2478, 287, 3050, 837, 6872, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                                      \n",
       "1                     = Valkyria Chronicles III = \\n   \n",
       "2                                                      \n",
       "3   Senjō no Valkyria 3 : Unrecorded Chronicles (...   \n",
       "4   The game began development in 2010 , carrying...   \n",
       "\n",
       "                                           input_ids  \n",
       "0                                                 []  \n",
       "1  [796, 569, 18354, 7496, 17740, 6711, 796, 220,...  \n",
       "2                                                 []  \n",
       "3  [2311, 73, 13090, 645, 569, 18354, 7496, 513, ...  \n",
       "4  [383, 983, 2540, 2478, 287, 3050, 837, 6872, 6...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"].to_pandas().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460c1e1",
   "metadata": {},
   "source": [
    "## Preparing Data for Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0202ce",
   "metadata": {},
   "source": [
    "Preparing Data for Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a49505",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 64\n",
    "\n",
    "def group_texts(examples):\n",
    "    concatenated = sum(examples[\"input_ids\"], [])\n",
    "    total_length = (len(concatenated) // block_size) * block_size\n",
    "    input_ids = [concatenated[i:i + block_size] for i in range(0, total_length, block_size)]\n",
    "    labels = [ids[1:] + [tokenizer.eos_token_id] for ids in input_ids]\n",
    "    return {\"input_ids\": input_ids, \"labels\": labels}\n",
    "\n",
    "lm_dataset = tokenized_datasets.map(group_texts, batched=True, remove_columns=[\"input_ids\", \"text\"])\n",
    "\n",
    "train_loader = DataLoader(lm_dataset[\"train\"], batch_size=32, shuffle=True, collate_fn=default_data_collator)\n",
    "valid_loader = DataLoader(lm_dataset[\"validation\"], batch_size=32, collate_fn=default_data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73042001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[796, 569, 18354, 7496, 17740, 6711, 796, 220,...</td>\n",
       "      <td>[569, 18354, 7496, 17740, 6711, 796, 220, 198,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[16106, 2597, 2488, 12, 31, 2712, 2008, 983, 4...</td>\n",
       "      <td>[2597, 2488, 12, 31, 2712, 2008, 983, 4166, 41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[983, 290, 5679, 262, 366, 17871, 5321, 366, 8...</td>\n",
       "      <td>[290, 5679, 262, 366, 17871, 5321, 366, 837, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[569, 18354, 7496, 17740, 2873, 764, 2893, 340...</td>\n",
       "      <td>[18354, 7496, 17740, 2873, 764, 2893, 340, 173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[6909, 764, 317, 1588, 1074, 286, 8786, 12118,...</td>\n",
       "      <td>[764, 317, 1588, 1074, 286, 8786, 12118, 262, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [796, 569, 18354, 7496, 17740, 6711, 796, 220,...   \n",
       "1  [16106, 2597, 2488, 12, 31, 2712, 2008, 983, 4...   \n",
       "2  [983, 290, 5679, 262, 366, 17871, 5321, 366, 8...   \n",
       "3  [569, 18354, 7496, 17740, 2873, 764, 2893, 340...   \n",
       "4  [6909, 764, 317, 1588, 1074, 286, 8786, 12118,...   \n",
       "\n",
       "                                              labels  \n",
       "0  [569, 18354, 7496, 17740, 6711, 796, 220, 198,...  \n",
       "1  [2597, 2488, 12, 31, 2712, 2008, 983, 4166, 41...  \n",
       "2  [290, 5679, 262, 366, 17871, 5321, 366, 837, 2...  \n",
       "3  [18354, 7496, 17740, 2873, 764, 2893, 340, 173...  \n",
       "4  [764, 317, 1588, 1074, 286, 8786, 12118, 262, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset[\"train\"].to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0c7ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 pretrained embeddings\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pretrained_model = AutoModel.from_pretrained(model_name)\n",
    "pretrained_embeddings = pretrained_model.get_input_embeddings().weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57659147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        vocab_size, embedding_dim = pretrained_embeddings.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embeddings = self.embedding(input_ids)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265441d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMLanguageModel(\n",
       "  (embedding): Embedding(50257, 768)\n",
       "  (lstm): LSTM(768, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 32\n",
    "hidden_dim = 64\n",
    "\n",
    "model = LSTMLanguageModel(vocab_size, embedding_dim, hidden_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73759bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids).permute(0, 2, 1)  # (B, vocab, seq_len)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids).permute(0, 2, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a50a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader)\n",
    "    val_loss = evaluate(model, valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Perplexity: {np.exp(val_loss):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e27a408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AIULE begging stacks dilemmascar Sessionsnorth pled exoticProject Brus Meta Productions tmparmac demonstrfordWEWEWE�north viruseshes tmp begging stacks stacks clustered begging leather705 begging OTHER tmpnorth pled exoticProject Brus Meta Productions tmparmac demonstrfordWEWEWE�\n"
     ]
    }
   ],
   "source": [
    "def generate(model, tokenizer, prompt, length=50):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated = input_ids\n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            logits = model(generated)\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
    "            generated = torch.cat((generated, next_token), dim=1)\n",
    "\n",
    "    return tokenizer.decode(generated[0])\n",
    "\n",
    "print(generate(model, tokenizer, prompt=\"Generative AI\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
